Model,MSE_y1,RMSE_y1,R2_y1,Adj_R2_y1,MSE_y2,RMSE_y2,R2_y2,Adj_R2_y2
linear outputs activation with adagrad optimizer and 1 batches,1.43,1.196,0.724,0.723,2366.23,48.644,0.709,0.723
linear outputs activation with adam optimizer and 1 batches,37.673,6.138,-6.285,-6.288,56156.933,236.975,-5.902,-6.288
linear outputs activation with nadam optimizer and 1 batches,0.617,0.785,0.881,0.881,940.854,30.673,0.884,0.881
linear outputs activation with rmsprop optimizer and 1 batches,0.061,0.246,0.988,0.988,262.969,16.216,0.968,0.988
linear outputs activation with adagrad optimizer and 32 batches,7.891,2.809,-0.526,-0.527,10579.811,102.858,-0.3,-0.527
linear outputs activation with adam optimizer and 32 batches,0.152,0.389,0.971,0.971,679.536,26.068,0.916,0.971
linear outputs activation with nadam optimizer and 32 batches,0.722,0.85,0.86,0.86,1545.146,39.308,0.81,0.86
linear outputs activation with rmsprop optimizer and 32 batches,0.052,0.228,0.99,0.99,215.286,14.673,0.974,0.99
linear outputs activation with adagrad optimizer and 10 batches,7.031,2.652,-0.359,-0.36,9517.364,97.557,-0.17,-0.36
linear outputs activation with adam optimizer and 10 batches,0.108,0.329,0.979,0.979,472.717,21.742,0.942,0.979
linear outputs activation with nadam optimizer and 10 batches,0.409,0.64,0.921,0.921,2950.789,54.321,0.637,0.921
linear outputs activation with rmsprop optimizer and 10 batches,0.034,0.185,0.993,0.993,240.776,15.517,0.97,0.993
linear outputs activation with adagrad optimizer and 5 batches,3.178,1.783,0.385,0.385,4381.957,66.196,0.461,0.385
linear outputs activation with adam optimizer and 5 batches,0.617,0.785,0.881,0.881,940.842,30.673,0.884,0.881
linear outputs activation with nadam optimizer and 5 batches,0.106,0.326,0.979,0.979,1182.528,34.388,0.855,0.979
linear outputs activation with rmsprop optimizer and 5 batches,0.034,0.183,0.994,0.994,178.934,13.377,0.978,0.994
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with adagrad optimizer and 1 batches",4.072,2.018,0.213,0.212,4862.26,69.73,0.402,0.212
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with adam optimizer and 1 batches",0.617,0.785,0.881,0.881,940.845,30.673,0.884,0.881
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with nadam optimizer and 1 batches",0.388,0.623,0.925,0.925,777.424,27.882,0.904,0.925
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with rmsprop optimizer and 1 batches",0.092,0.303,0.982,0.982,281.56,16.78,0.965,0.982
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with adagrad optimizer and 32 batches",5.028,2.242,0.028,0.027,6200.833,78.745,0.238,0.027
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with adam optimizer and 32 batches",0.093,0.305,0.982,0.982,410.074,20.25,0.95,0.982
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with nadam optimizer and 32 batches",0.32,0.565,0.938,0.938,837.823,28.945,0.897,0.938
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with rmsprop optimizer and 32 batches",0.056,0.236,0.989,0.989,245.669,15.674,0.97,0.989
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with adagrad optimizer and 10 batches",11.311,3.363,-1.187,-1.188,15148.699,123.08,-0.862,-1.188
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with adam optimizer and 10 batches",0.115,0.34,0.978,0.978,887.671,29.794,0.891,0.978
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with nadam optimizer and 10 batches",3.057,1.748,0.409,0.409,6098.899,78.095,0.25,0.409
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with rmsprop optimizer and 10 batches",0.046,0.215,0.991,0.991,221.938,14.898,0.973,0.991
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with adagrad optimizer and 5 batches",5.271,2.296,-0.019,-0.02,6612.804,81.319,0.187,-0.02
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with adam optimizer and 5 batches",0.108,0.329,0.979,0.979,547.062,23.389,0.933,0.979
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with nadam optimizer and 5 batches",0.084,0.29,0.984,0.984,265.288,16.288,0.967,0.984
"<LeakyReLU name=leaky_re_lu_0.01, built=True> outputs activation with rmsprop optimizer and 5 batches",0.047,0.217,0.991,0.991,541.724,23.275,0.933,0.991
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with adagrad optimizer and 1 batches",1.383,1.176,0.733,0.733,1988.302,44.59,0.756,0.733
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with adam optimizer and 1 batches",0.617,0.785,0.881,0.881,940.844,30.673,0.884,0.881
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with nadam optimizer and 1 batches",0.617,0.785,0.881,0.881,940.851,30.673,0.884,0.881
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with rmsprop optimizer and 1 batches",0.043,0.208,0.992,0.992,502.014,22.406,0.938,0.992
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with adagrad optimizer and 32 batches",15.4,3.924,-1.978,-1.979,20223.605,142.21,-1.485,-1.979
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with adam optimizer and 32 batches",0.054,0.232,0.99,0.99,387.969,19.697,0.952,0.99
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with nadam optimizer and 32 batches",0.206,0.454,0.96,0.96,724.391,26.915,0.911,0.96
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with rmsprop optimizer and 32 batches",0.03,0.174,0.994,0.994,117.488,10.839,0.986,0.994
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with adagrad optimizer and 10 batches",2.002,1.415,0.613,0.613,2769.756,52.628,0.66,0.613
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with adam optimizer and 10 batches",0.617,0.785,0.881,0.881,940.837,30.673,0.884,0.881
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with nadam optimizer and 10 batches",0.141,0.376,0.973,0.973,1103.061,33.212,0.864,0.973
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with rmsprop optimizer and 10 batches",0.045,0.211,0.991,0.991,243.561,15.606,0.97,0.991
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with adagrad optimizer and 5 batches",3.284,1.812,0.365,0.365,4263.249,65.294,0.476,0.365
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with adam optimizer and 5 batches",0.617,0.785,0.881,0.881,940.842,30.673,0.884,0.881
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with nadam optimizer and 5 batches",0.038,0.194,0.993,0.993,446.716,21.136,0.945,0.993
"<LeakyReLU name=leaky_re_lu_0.1, built=True> outputs activation with rmsprop optimizer and 5 batches",0.031,0.177,0.994,0.994,164.104,12.81,0.98,0.994
elu outputs activation with adagrad optimizer and 1 batches,177.779,13.333,-33.138,-33.155,237611.978,487.455,-28.265,-33.155
elu outputs activation with adam optimizer and 1 batches,177.804,13.334,-33.143,-33.16,237611.978,487.455,-28.265,-33.16
elu outputs activation with nadam optimizer and 1 batches,0.598,0.773,0.885,0.885,969.887,31.143,0.881,0.885
elu outputs activation with rmsprop optimizer and 1 batches,177.804,13.334,-33.143,-33.16,237611.978,487.455,-28.265,-33.16
elu outputs activation with adagrad optimizer and 32 batches,160.241,12.659,-29.77,-29.786,214467.468,463.106,-25.414,-29.786
elu outputs activation with adam optimizer and 32 batches,177.804,13.334,-33.143,-33.16,237611.978,487.455,-28.265,-33.16
elu outputs activation with nadam optimizer and 32 batches,177.804,13.334,-33.143,-33.16,237611.978,487.455,-28.265,-33.16
elu outputs activation with rmsprop optimizer and 32 batches,0.031,0.175,0.994,0.994,150.179,12.255,0.982,0.994
elu outputs activation with adagrad optimizer and 10 batches,170.65,13.063,-31.769,-31.785,233487.568,483.206,-27.757,-31.785
elu outputs activation with adam optimizer and 10 batches,177.804,13.334,-33.143,-33.16,237611.978,487.455,-28.265,-33.16
elu outputs activation with nadam optimizer and 10 batches,177.804,13.334,-33.143,-33.16,237611.978,487.455,-28.265,-33.16
elu outputs activation with rmsprop optimizer and 10 batches,0.026,0.162,0.995,0.995,130.759,11.435,0.984,0.995
elu outputs activation with adagrad optimizer and 5 batches,0.228,0.478,0.956,0.956,727.123,26.965,0.91,0.956
elu outputs activation with adam optimizer and 5 batches,177.804,13.334,-33.143,-33.16,237611.978,487.455,-28.265,-33.16
elu outputs activation with nadam optimizer and 5 batches,0.032,0.179,0.994,0.994,445.508,21.107,0.945,0.994
elu outputs activation with rmsprop optimizer and 5 batches,0.032,0.18,0.994,0.994,111.66,10.567,0.986,0.994
tanh outputs activation with adagrad optimizer and 1 batches,105.476,10.27,-19.254,-19.264,156377.179,395.446,-18.26,-19.264
tanh outputs activation with adam optimizer and 1 batches,102.946,10.146,-18.768,-18.778,175043.858,418.382,-20.559,-18.778
tanh outputs activation with nadam optimizer and 1 batches,119.843,10.947,-22.013,-22.024,139714.645,373.784,-16.208,-22.024
tanh outputs activation with rmsprop optimizer and 1 batches,100.017,10.001,-18.206,-18.215,144523.734,380.163,-16.8,-18.215
tanh outputs activation with adagrad optimizer and 32 batches,92.661,9.626,-16.793,-16.802,116351.504,341.103,-13.33,-16.802
tanh outputs activation with adam optimizer and 32 batches,83.71,9.149,-15.074,-15.082,123785.935,351.832,-14.246,-15.082
tanh outputs activation with nadam optimizer and 32 batches,98.836,9.942,-17.979,-17.988,126994.738,356.363,-14.641,-17.988
tanh outputs activation with rmsprop optimizer and 32 batches,88.888,9.428,-16.069,-16.077,132013.379,363.336,-15.259,-16.077
tanh outputs activation with adagrad optimizer and 10 batches,94.433,9.718,-17.133,-17.143,122611.772,350.16,-14.101,-17.143
tanh outputs activation with adam optimizer and 10 batches,117.059,10.819,-21.478,-21.489,155327.641,394.116,-18.131,-21.489
tanh outputs activation with nadam optimizer and 10 batches,112.099,10.588,-20.526,-20.536,137944.712,371.409,-15.99,-20.536
tanh outputs activation with rmsprop optimizer and 10 batches,112.068,10.586,-20.52,-20.531,140311.503,374.582,-16.281,-20.531
tanh outputs activation with adagrad optimizer and 5 batches,103.676,10.182,-18.908,-18.918,133967.904,366.016,-15.5,-18.918
tanh outputs activation with adam optimizer and 5 batches,111.579,10.563,-20.426,-20.437,143950.684,379.408,-16.729,-20.437
tanh outputs activation with nadam optimizer and 5 batches,81.915,9.051,-14.73,-14.738,155388.853,394.194,-18.138,-14.738
tanh outputs activation with rmsprop optimizer and 5 batches,105.26,10.26,-19.213,-19.223,140629.999,375.007,-16.32,-19.223
"<LeakyReLU name=leaky_re_lu, built=True> outputs activation with rmsprop optimizer and 5 batches",0.042,0.205,0.992,0.992,165.625,12.87,0.98,0.992
"<LeakyReLU name=leaky_re_lu, built=True> outputs activation with rmsprop optimizer and 5 batches",0.035,0.188,0.993,0.993,80.554,8.975,0.99,0.993
